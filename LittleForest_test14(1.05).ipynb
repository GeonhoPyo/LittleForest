{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import tarfile\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy.stats import skew\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error, r2_score\n",
    "from sklearn.linear_model import Lasso, LassoCV, MultiTaskLassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import optimizers\n",
    "from keras.initializers import lecun_normal\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_val_predict\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission-----------\n",
      "['id', 'hhb', 'hbo2', 'ca', 'na']\n",
      "(10000, 5)\n",
      "test-----------\n",
      "['id', 'rho', '650_src', '660_src', '670_src', '680_src', '690_src', '700_src', '710_src', '720_src', '730_src', '740_src', '750_src', '760_src', '770_src', '780_src', '790_src', '800_src', '810_src', '820_src', '830_src', '840_src', '850_src', '860_src', '870_src', '880_src', '890_src', '900_src', '910_src', '920_src', '930_src', '940_src', '950_src', '960_src', '970_src', '980_src', '990_src', '650_dst', '660_dst', '670_dst', '680_dst', '690_dst', '700_dst', '710_dst', '720_dst', '730_dst', '740_dst', '750_dst', '760_dst', '770_dst', '780_dst', '790_dst', '800_dst', '810_dst', '820_dst', '830_dst', '840_dst', '850_dst', '860_dst', '870_dst', '880_dst', '890_dst', '900_dst', '910_dst', '920_dst', '930_dst', '940_dst', '950_dst', '960_dst', '970_dst', '980_dst', '990_dst']\n",
      "(10000, 72)\n",
      "train-----------\n",
      "['id', 'rho', '650_src', '660_src', '670_src', '680_src', '690_src', '700_src', '710_src', '720_src', '730_src', '740_src', '750_src', '760_src', '770_src', '780_src', '790_src', '800_src', '810_src', '820_src', '830_src', '840_src', '850_src', '860_src', '870_src', '880_src', '890_src', '900_src', '910_src', '920_src', '930_src', '940_src', '950_src', '960_src', '970_src', '980_src', '990_src', '650_dst', '660_dst', '670_dst', '680_dst', '690_dst', '700_dst', '710_dst', '720_dst', '730_dst', '740_dst', '750_dst', '760_dst', '770_dst', '780_dst', '790_dst', '800_dst', '810_dst', '820_dst', '830_dst', '840_dst', '850_dst', '860_dst', '870_dst', '880_dst', '890_dst', '900_dst', '910_dst', '920_dst', '930_dst', '940_dst', '950_dst', '960_dst', '970_dst', '980_dst', '990_dst', 'hhb', 'hbo2', 'ca', 'na']\n",
      "(10000, 76)\n"
     ]
    }
   ],
   "source": [
    "# CSV TO DATA\n",
    "def csvToData(csv_file):\n",
    "    df = pd.read_csv(csv_file, header = 0)\n",
    "    column = list(df.columns.values)\n",
    "    data = df.values\n",
    "    return column, data\n",
    "\n",
    "sample_column, sample_csv_data = csvToData(\"data/sample_submission.csv\")\n",
    "test_column, test_csv_data = csvToData(\"data/test.csv\")\n",
    "train_column, train_csv_data = csvToData(\"data/train.csv\")\n",
    "print('sample_submission-----------')\n",
    "print(sample_column)\n",
    "print(sample_csv_data.shape)\n",
    "print('test-----------')\n",
    "print(test_column)\n",
    "print(test_csv_data.shape)\n",
    "print('train-----------')\n",
    "print(train_column)\n",
    "print(train_csv_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  hhb  hbo2  ca  na\n",
       "0  10000    0     0   0   0\n",
       "1  10001    0     0   0   0\n",
       "2  10002    0     0   0   0\n",
       "3  10003    0     0   0   0\n",
       "4  10004    0     0   0   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.DataFrame(sample_csv_data, columns=sample_column)\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 72)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rho</th>\n",
       "      <th>650_src</th>\n",
       "      <th>660_src</th>\n",
       "      <th>670_src</th>\n",
       "      <th>680_src</th>\n",
       "      <th>690_src</th>\n",
       "      <th>700_src</th>\n",
       "      <th>710_src</th>\n",
       "      <th>720_src</th>\n",
       "      <th>...</th>\n",
       "      <th>900_dst</th>\n",
       "      <th>910_dst</th>\n",
       "      <th>920_dst</th>\n",
       "      <th>930_dst</th>\n",
       "      <th>940_dst</th>\n",
       "      <th>950_dst</th>\n",
       "      <th>960_dst</th>\n",
       "      <th>970_dst</th>\n",
       "      <th>980_dst</th>\n",
       "      <th>990_dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.15406</td>\n",
       "      <td>0.23275</td>\n",
       "      <td>0.30977</td>\n",
       "      <td>0.42949</td>\n",
       "      <td>0.51264</td>\n",
       "      <td>0.62558</td>\n",
       "      <td>0.74340</td>\n",
       "      <td>0.85418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.432248e-14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.332117e-15</td>\n",
       "      <td>1.429966e-14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.320236e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.48552</td>\n",
       "      <td>0.56939</td>\n",
       "      <td>0.67575</td>\n",
       "      <td>0.79089</td>\n",
       "      <td>0.85114</td>\n",
       "      <td>0.92581</td>\n",
       "      <td>0.98071</td>\n",
       "      <td>0.98177</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036013e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.830975e-14</td>\n",
       "      <td>1.114337e-13</td>\n",
       "      <td>4.825731e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.282485e-14</td>\n",
       "      <td>7.348414e-14</td>\n",
       "      <td>1.259055e-13</td>\n",
       "      <td>2.349874e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.46883</td>\n",
       "      <td>0.56085</td>\n",
       "      <td>0.62442</td>\n",
       "      <td>0.73172</td>\n",
       "      <td>0.81724</td>\n",
       "      <td>0.91517</td>\n",
       "      <td>0.94801</td>\n",
       "      <td>0.99108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.569208e-11</td>\n",
       "      <td>6.242378e-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.219010e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.07517</td>\n",
       "      <td>0.10226</td>\n",
       "      <td>0.14905</td>\n",
       "      <td>0.16182</td>\n",
       "      <td>0.19659</td>\n",
       "      <td>0.26085</td>\n",
       "      <td>0.36753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.651177e-11</td>\n",
       "      <td>7.282747e-12</td>\n",
       "      <td>5.010879e-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.571023e-11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.304247e-12</td>\n",
       "      <td>4.106134e-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.01649</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00105</td>\n",
       "      <td>0.01975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.732057e-17</td>\n",
       "      <td>4.110605e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.910775e-16</td>\n",
       "      <td>2.215673e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   rho  650_src  660_src  670_src  680_src  690_src  700_src  \\\n",
       "0  10000.0  15.0  0.15406  0.23275  0.30977  0.42949  0.51264  0.62558   \n",
       "1  10001.0  15.0  0.48552  0.56939  0.67575  0.79089  0.85114  0.92581   \n",
       "2  10002.0  10.0  0.46883  0.56085  0.62442  0.73172  0.81724  0.91517   \n",
       "3  10003.0  10.0  0.06905  0.07517  0.10226  0.14905  0.16182  0.19659   \n",
       "4  10004.0  25.0  0.00253  0.00757  0.01649  0.00128  0.00000  0.00000   \n",
       "\n",
       "   710_src  720_src  ...       900_dst       910_dst       920_dst  \\\n",
       "0  0.74340  0.85418  ...  0.000000e+00  0.000000e+00  1.432248e-14   \n",
       "1  0.98071  0.98177  ...  1.036013e-13           NaN  2.830975e-14   \n",
       "2  0.94801  0.99108  ...           NaN           NaN           NaN   \n",
       "3  0.26085  0.36753  ...  1.651177e-11  7.282747e-12  5.010879e-12   \n",
       "4  0.00105  0.01975  ...  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "        930_dst       940_dst       950_dst       960_dst       970_dst  \\\n",
       "0  0.000000e+00  0.000000e+00  6.332117e-15  1.429966e-14  0.000000e+00   \n",
       "1  1.114337e-13  4.825731e-14           NaN  2.282485e-14  7.348414e-14   \n",
       "2           NaN  1.569208e-11  6.242378e-12           NaN  1.219010e-11   \n",
       "3           NaN  1.571023e-11  0.000000e+00  0.000000e+00  3.304247e-12   \n",
       "4  0.000000e+00  3.732057e-17  4.110605e-17  0.000000e+00  0.000000e+00   \n",
       "\n",
       "        980_dst       990_dst  \n",
       "0           NaN  7.320236e-14  \n",
       "1  1.259055e-13  2.349874e-13  \n",
       "2           NaN           NaN  \n",
       "3  4.106134e-11           NaN  \n",
       "4  1.910775e-16  2.215673e-15  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(test_csv_data, columns=test_column)\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rho</th>\n",
       "      <th>650_src</th>\n",
       "      <th>660_src</th>\n",
       "      <th>670_src</th>\n",
       "      <th>680_src</th>\n",
       "      <th>690_src</th>\n",
       "      <th>700_src</th>\n",
       "      <th>710_src</th>\n",
       "      <th>720_src</th>\n",
       "      <th>...</th>\n",
       "      <th>940_dst</th>\n",
       "      <th>950_dst</th>\n",
       "      <th>960_dst</th>\n",
       "      <th>970_dst</th>\n",
       "      <th>980_dst</th>\n",
       "      <th>990_dst</th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.37950</td>\n",
       "      <td>0.42993</td>\n",
       "      <td>0.52076</td>\n",
       "      <td>0.57166</td>\n",
       "      <td>0.67818</td>\n",
       "      <td>0.75476</td>\n",
       "      <td>0.83580</td>\n",
       "      <td>0.93623</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067504e-18</td>\n",
       "      <td>5.998949e-18</td>\n",
       "      <td>4.378513e-17</td>\n",
       "      <td>5.59</td>\n",
       "      <td>4.32</td>\n",
       "      <td>8.92</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01813</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.00321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343132e-08</td>\n",
       "      <td>6.112685e-09</td>\n",
       "      <td>2.130547e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.710091e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.83</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.02416</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05843</td>\n",
       "      <td>0.09015</td>\n",
       "      <td>0.14944</td>\n",
       "      <td>0.18578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.329725e-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.64</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.27503</td>\n",
       "      <td>0.31281</td>\n",
       "      <td>0.32898</td>\n",
       "      <td>0.41041</td>\n",
       "      <td>0.46587</td>\n",
       "      <td>0.52769</td>\n",
       "      <td>0.64369</td>\n",
       "      <td>0.73562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.245998e-10</td>\n",
       "      <td>1.299511e-10</td>\n",
       "      <td>7.782625e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.088921e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.67</td>\n",
       "      <td>4.01</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.01521</td>\n",
       "      <td>1.00872</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>0.98874</td>\n",
       "      <td>1.01773</td>\n",
       "      <td>1.01632</td>\n",
       "      <td>1.00009</td>\n",
       "      <td>0.98217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.457955e-13</td>\n",
       "      <td>8.769053e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.330237e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.97</td>\n",
       "      <td>4.41</td>\n",
       "      <td>10.78</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   rho  650_src  660_src  670_src  680_src  690_src  700_src  710_src  \\\n",
       "0  0.0  25.0  0.37950  0.42993  0.52076  0.57166  0.67818  0.75476  0.83580   \n",
       "1  1.0  10.0  0.00000  0.00000  0.01813  0.00000  0.00000  0.01974  0.00321   \n",
       "2  2.0  25.0  0.00000  0.03289  0.02416  0.03610  0.05843  0.09015  0.14944   \n",
       "3  3.0  10.0  0.27503  0.31281  0.32898  0.41041  0.46587  0.52769  0.64369   \n",
       "4  4.0  15.0  1.01521  1.00872  0.98930  0.98874  1.01773  1.01632  1.00009   \n",
       "\n",
       "   720_src  ...       940_dst       950_dst       960_dst       970_dst  \\\n",
       "0  0.93623  ...           NaN  0.000000e+00           NaN  1.067504e-18   \n",
       "1  0.00000  ...  1.343132e-08  6.112685e-09  2.130547e-09           NaN   \n",
       "2  0.18578  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3  0.73562  ...  2.245998e-10  1.299511e-10  7.782625e-11           NaN   \n",
       "4  0.98217  ...  1.457955e-13  8.769053e-14           NaN  1.330237e-13   \n",
       "\n",
       "        980_dst       990_dst    hhb  hbo2     ca    na  \n",
       "0  5.998949e-18  4.378513e-17   5.59  4.32   8.92  4.29  \n",
       "1  9.710091e-09           NaN   0.00  2.83   7.25  4.64  \n",
       "2  1.329725e-18           NaN  10.64  3.00   8.40  5.16  \n",
       "3  4.088921e-10           NaN   5.67  4.01   5.05  4.35  \n",
       "4           NaN           NaN  11.97  4.41  10.78  2.42  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train_csv_data, columns=train_column)\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list=['650_src', '660_src', '670_src', '680_src', '690_src', '700_src', '710_src', '720_src', '730_src', \n",
    "          '740_src', '750_src', '760_src', '770_src', '780_src', '790_src', '800_src', '810_src', '820_src', \n",
    "          '830_src', '840_src', '850_src', '860_src', '870_src', '880_src', '890_src', '900_src', '910_src', \n",
    "          '920_src', '930_src', '940_src', '950_src', '960_src', '970_src', '980_src', '990_src']\n",
    "dst_list=['650_dst', '660_dst', '670_dst', '680_dst', '690_dst', '700_dst', '710_dst', '720_dst', '730_dst', \n",
    "          '740_dst', '750_dst', '760_dst', '770_dst', '780_dst', '790_dst', '800_dst', '810_dst', '820_dst', \n",
    "          '830_dst', '840_dst', '850_dst', '860_dst', '870_dst', '880_dst', '890_dst', '900_dst', '910_dst', \n",
    "          '920_dst', '930_dst', '940_dst', '950_dst', '960_dst', '970_dst', '980_dst', '990_dst']\n",
    "rho_list=[10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:04<00:00, 2213.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:04<00:00, 2239.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "alpha=train_data[dst_list]\n",
    "beta=test_data[dst_list]\n",
    "\n",
    "for i in tqdm(train_data.index):\n",
    "    alpha.loc[i] = alpha.loc[i].interpolate()\n",
    "    \n",
    "for i in tqdm(test_data.index):\n",
    "    beta.loc[i] = beta.loc[i].interpolate()\n",
    "    \n",
    "alpha.loc[alpha['700_dst'].isnull(),'700_dst']=alpha.loc[alpha['700_dst'].isnull(),'710_dst']\n",
    "alpha.loc[alpha['690_dst'].isnull(),'690_dst']=alpha.loc[alpha['690_dst'].isnull(),'700_dst']\n",
    "alpha.loc[alpha['680_dst'].isnull(),'680_dst']=alpha.loc[alpha['680_dst'].isnull(),'690_dst']\n",
    "alpha.loc[alpha['670_dst'].isnull(),'670_dst']=alpha.loc[alpha['670_dst'].isnull(),'680_dst']\n",
    "alpha.loc[alpha['660_dst'].isnull(),'660_dst']=alpha.loc[alpha['660_dst'].isnull(),'670_dst']\n",
    "alpha.loc[alpha['650_dst'].isnull(),'650_dst']=alpha.loc[alpha['650_dst'].isnull(),'660_dst']\n",
    "\n",
    "beta.loc[beta['700_dst'].isnull(),'700_dst']=beta.loc[beta['700_dst'].isnull(),'710_dst']\n",
    "beta.loc[beta['690_dst'].isnull(),'690_dst']=beta.loc[beta['690_dst'].isnull(),'700_dst']\n",
    "beta.loc[beta['680_dst'].isnull(),'680_dst']=beta.loc[beta['680_dst'].isnull(),'690_dst']\n",
    "beta.loc[beta['670_dst'].isnull(),'670_dst']=beta.loc[beta['670_dst'].isnull(),'680_dst']\n",
    "beta.loc[beta['660_dst'].isnull(),'660_dst']=beta.loc[beta['660_dst'].isnull(),'670_dst']\n",
    "beta.loc[beta['650_dst'].isnull(),'650_dst']=beta.loc[beta['650_dst'].isnull(),'660_dst']\n",
    "\n",
    "train_data[dst_list] = np.array(alpha)\n",
    "test_data[dst_list] = np.array(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dst_list:\n",
    "    train_data[col] = train_data[col] * (train_data['rho'] ** 2)\n",
    "    test_data[col] = test_data[col] * (test_data['rho']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_feature_names=[]\n",
    "for i in range(650, 1000, 10):\n",
    "    gap_feature_names.append(str(i) + '_gap')\n",
    "\n",
    "alpha=pd.DataFrame(np.array(train_data[src_list]) - np.array(train_data[dst_list]), columns=gap_feature_names, index=train_data.index)\n",
    "beta=pd.DataFrame(np.array(test_data[src_list]) - np.array(test_data[dst_list]), columns=gap_feature_names, index=test_data.index)\n",
    "\n",
    "train_data=pd.concat((train_data, alpha), axis=1)\n",
    "test_data=pd.concat((test_data, beta), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-10\n",
    "\n",
    "for dst_col, src_col in zip(dst_list, src_list):\n",
    "    dst_val=train_data[dst_col]\n",
    "    src_val=train_data[src_col] + epsilon\n",
    "    \n",
    "    delta_ratio = dst_val / src_val\n",
    "    train_data[dst_col + '_' + src_col + '_ratio'] = delta_ratio\n",
    "    \n",
    "    dst_val=test_data[dst_col]\n",
    "    src_val=test_data[src_col] + epsilon\n",
    "    \n",
    "    delta_ratio = dst_val / src_val\n",
    "    test_data[dst_col + '_' + src_col + '_ratio'] = delta_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:13<00:00, 735.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:13<00:00, 728.64it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha_real=train_data[dst_list]\n",
    "alpha_imag=train_data[dst_list]\n",
    "\n",
    "beta_real=test_data[dst_list]\n",
    "beta_imag=test_data[dst_list]\n",
    "\n",
    "for i in tqdm(alpha_real.index):\n",
    "    alpha_real.loc[i]=alpha_real.loc[i] - alpha_real.loc[i].mean()\n",
    "    alpha_imag.loc[i]=alpha_imag.loc[i] - alpha_real.loc[i].mean()\n",
    "    \n",
    "    alpha_real.loc[i] = np.fft.fft(alpha_real.loc[i], norm='ortho').real\n",
    "    alpha_imag.loc[i] = np.fft.fft(alpha_imag.loc[i], norm='ortho').imag\n",
    "\n",
    "    \n",
    "for i in tqdm(beta_real.index):\n",
    "    beta_real.loc[i]=beta_real.loc[i] - beta_real.loc[i].mean()\n",
    "    beta_imag.loc[i]=beta_imag.loc[i] - beta_imag.loc[i].mean()\n",
    "    \n",
    "    beta_real.loc[i] = np.fft.fft(beta_real.loc[i], norm='ortho').real\n",
    "    beta_imag.loc[i] = np.fft.fft(beta_imag.loc[i], norm='ortho').imag\n",
    "    \n",
    "real_part=[]\n",
    "imag_part=[]\n",
    "\n",
    "for col in dst_list:\n",
    "    real_part.append(col + '_fft_real')\n",
    "    imag_part.append(col + '_fft_imag')\n",
    "    \n",
    "alpha_real.columns=real_part\n",
    "alpha_imag.columns=imag_part\n",
    "alpha = pd.concat((alpha_real, alpha_imag), axis=1)\n",
    "\n",
    "beta_real.columns=real_part\n",
    "beta_imag.columns=imag_part\n",
    "beta=pd.concat((beta_real, beta_imag), axis=1)\n",
    "\n",
    "train_data=pd.concat((train_data, alpha), axis=1)\n",
    "test_data=pd.concat((test_data, beta), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(train_data).values.any(),np.isnan(test_data).values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2456, 216) (2509, 216) (2478, 216) (2557, 216)\n",
      "(2519, 212) (2509, 212) (2434, 212) (2538, 212)\n"
     ]
    }
   ],
   "source": [
    "#rho 별로 분류\n",
    "idx_10 = train_data['rho'] == 10\n",
    "idx_15 = train_data['rho'] == 15\n",
    "idx_20 = train_data['rho'] == 20\n",
    "idx_25 = train_data['rho'] == 25\n",
    "train_data_10 = train_data.loc[idx_10,:]\n",
    "train_data_15 = train_data.loc[idx_15,:]\n",
    "train_data_20 = train_data.loc[idx_20,:]\n",
    "train_data_25 = train_data.loc[idx_25,:]\n",
    "print(train_data_10.shape, train_data_15.shape, train_data_20.shape, train_data_25.shape)\n",
    "\n",
    "idx_test_10 = test_data['rho'] == 10\n",
    "idx_test_15 = test_data['rho'] == 15\n",
    "idx_test_20 = test_data['rho'] == 20\n",
    "idx_test_25 = test_data['rho'] == 25\n",
    "test_data_10 = test_data.loc[idx_test_10,:]\n",
    "test_data_15 = test_data.loc[idx_test_15,:]\n",
    "test_data_20 = test_data.loc[idx_test_20,:]\n",
    "test_data_25 = test_data.loc[idx_test_25,:]\n",
    "print(test_data_10.shape, test_data_15.shape, test_data_20.shape, test_data_25.shape)\n",
    "\n",
    "#sample Code 용 _10\n",
    "x_train_sample_10 = train_data_10.loc[:, 'rho':] # train dataset\n",
    "x_train_sample_10.drop(['hhb','hbo2','ca','na'], axis='columns', inplace=True)\n",
    "y_train_sample_10 = train_data_10.loc[:, 'hhb':'na'] # train labels\n",
    "x_train_sample_10.shape, y_train_sample_10.shape\n",
    "test_sample_10 = copy.deepcopy(test_data_10)\n",
    "\n",
    "#sample Code 용 _15\n",
    "x_train_sample_15 = train_data_15.loc[:, 'rho':] # train dataset\n",
    "x_train_sample_15.drop(['hhb','hbo2','ca','na'], axis='columns', inplace=True)\n",
    "y_train_sample_15 = train_data_15.loc[:, 'hhb':'na'] # train labels\n",
    "x_train_sample_15.shape, y_train_sample_15.shape\n",
    "test_sample_15 = copy.deepcopy(test_data_15)\n",
    "\n",
    "#sample Code 용 _20\n",
    "x_train_sample_20 = train_data_20.loc[:, 'rho':] # train dataset\n",
    "x_train_sample_20.drop(['hhb','hbo2','ca','na'], axis='columns', inplace=True)\n",
    "y_train_sample_20 = train_data_20.loc[:, 'hhb':'na'] # train labels\n",
    "x_train_sample_20.shape, y_train_sample_20.shape\n",
    "test_sample_20 = copy.deepcopy(test_data_20)\n",
    "\n",
    "#sample Code 용 _25\n",
    "x_train_sample_25 = train_data_25.loc[:, 'rho':] # train dataset\n",
    "x_train_sample_25.drop(['hhb','hbo2','ca','na'], axis='columns', inplace=True)\n",
    "y_train_sample_25 = train_data_25.loc[:, 'hhb':'na'] # train labels\n",
    "x_train_sample_25.shape, y_train_sample_25.shape\n",
    "test_sample_25 = copy.deepcopy(test_data_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample_code\n",
    "avr_valid_mse = 0\n",
    "def test_train_model(x_data, y_data, k=5):\n",
    "    models = []\n",
    "    \n",
    "    k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(x_data):\n",
    "        \n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "    \n",
    "        d_train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "        d_val = xgb.DMatrix(data = x_val, label = y_val)\n",
    "        \n",
    "        wlist = [(d_train, 'train'), (d_val, 'eval')]\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'seed':777\n",
    "            }\n",
    "        model = xgb.train(params=params, dtrain=d_train, num_boost_round=400, verbose_eval=400, evals=wlist)\n",
    "        models.append(model)\n",
    "        \n",
    "        \n",
    "\n",
    "    return models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample_code\n",
    "avr_valid_mse = 0\n",
    "def test_train_model_ca_na(x_data, y_data, k=5):\n",
    "    models = []\n",
    "    \n",
    "    k_fold = KFold(n_splits=k, shuffle=True, random_state=123)\n",
    "    \n",
    "    for train_idx, val_idx in k_fold.split(x_data):\n",
    "        \n",
    "        x_train, y_train = x_data.iloc[train_idx], y_data.iloc[train_idx]\n",
    "        x_val, y_val = x_data.iloc[val_idx], y_data.iloc[val_idx]\n",
    "    \n",
    "        d_train = xgb.DMatrix(data = x_train, label = y_train)\n",
    "        d_val = xgb.DMatrix(data = x_val, label = y_val)\n",
    "        \n",
    "        wlist = [(d_train, 'train'), (d_val, 'eval')]\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'seed':777\n",
    "            }\n",
    "        model = xgb.train(params=params, dtrain=d_train, num_boost_round=600, verbose_eval=600, evals=wlist)\n",
    "        models.append(model)\n",
    "        \n",
    "        \n",
    "\n",
    "    return models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist = {}\n",
    "test_sample = copy.deepcopy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'object' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-810de3c9c2da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrebuilddata\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'hbo2'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'object' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "test_pred = np.array()\n",
    "def rebuilddata (col, x_train_sample, y_train_sample, rho) :\n",
    "    print(rho)\n",
    "    print(col)\n",
    "    if (col == 'hbo2') :\n",
    "        modellist[col] = test_train_model(x_train_sample, y_train_sample[col])\n",
    "        preds = []\n",
    "        for model in modellist[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(test_sample.loc[test_sample.rho==rho, 'rho':'990_dst_fft_imag'])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "    elif col == 'hhb' :\n",
    "        modellist[col] = test_train_model(x_train_sample, y_train_sample[col])\n",
    "        preds = []\n",
    "        for model in modellist[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(test_sample.loc[test_sample.rho==rho, 'rho':'hbo2'])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "    elif col == 'na' :\n",
    "        modellist[col] = test_train_model(x_train_sample, y_train_sample[col])\n",
    "        preds = []\n",
    "        for model in modellist[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(test_sample.loc[test_sample.rho==rho, 'rho':'hhb_hbo2_gap'])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "    elif col =='ca' :\n",
    "        modellist[col] = test_train_model(x_train_sample, y_train_sample[col])\n",
    "        preds = []\n",
    "        for model in modellist[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(test_sample.loc[test_sample.rho==rho, 'rho':'na'])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "    test_pred = pred\n",
    "    test_sample.loc[test_sample.rho==rho,col] = pred\n",
    "    if rho == 10 :\n",
    "        x_train_sample_10[col] = train_data_10[col] \n",
    "        return x_train_sample_10\n",
    "    elif rho == 15 :\n",
    "        x_train_sample_15[col] = train_data_15[col]\n",
    "        return x_train_sample_15\n",
    "    elif rho == 20 :\n",
    "        x_train_sample_20[col] = train_data_20[col]\n",
    "        return x_train_sample_20\n",
    "    elif rho == 25 :\n",
    "        x_train_sample_25[col] = train_data_25[col]\n",
    "        return x_train_sample_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho in rho_list :\n",
    "    if rho == 10 :\n",
    "        x_train_sample_10 = rebuilddata('hbo2',x_train_sample_10,y_train_sample_10,rho)\n",
    "        x_train_sample_10 = rebuilddata('hhb',x_train_sample_10,y_train_sample_10,rho)\n",
    "    elif rho == 15 :\n",
    "        x_train_sample_15 = rebuilddata('hbo2',x_train_sample_15,y_train_sample_15,rho)\n",
    "        x_train_sample_15 = rebuilddata('hhb',x_train_sample_15,y_train_sample_15,rho)\n",
    "    elif rho == 20 :\n",
    "        x_train_sample_20 = rebuilddata('hbo2',x_train_sample_20,y_train_sample_20,rho)\n",
    "        x_train_sample_20 = rebuilddata('hhb',x_train_sample_20,y_train_sample_20,rho)\n",
    "    elif rho == 25 :\n",
    "        x_train_sample_25 = rebuilddata('hbo2',x_train_sample_25,y_train_sample_25,rho)\n",
    "        x_train_sample_25 = rebuilddata('hhb',x_train_sample_25,y_train_sample_25,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sample = copy.deepcopy(train_data)\n",
    "for rho in rho_list :\n",
    "    if rho == 10 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_10.loc[:,:]\n",
    "    elif rho == 15 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_15.loc[:,:]\n",
    "    elif rho == 20 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_20.loc[:,:]\n",
    "    elif rho == 25 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_25.loc[:,:]\n",
    "        \n",
    "print(x_train_sample.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_drop_na = copy.deepcopy(train_data)\n",
    "\n",
    "train_sample_drop_na = train_sample_drop_na[train_sample_drop_na.na != 0]\n",
    "x_train_sample_drop_na = train_sample_drop_na.loc[:, 'rho':] # train dataset\n",
    "x_train_sample_drop_na.drop(['hhb','hbo2','ca','na'], axis='columns', inplace=True)\n",
    "y_train_sample_drop_na = train_sample_drop_na.loc[:, 'hhb':'na'] # train labels\n",
    "x_train_sample_drop_na['hhb'] = x_train_sample['hhb']\n",
    "x_train_sample_drop_na['hbo2'] = x_train_sample['hbo2']\n",
    "print(x_train_sample_drop_na.shape, y_train_sample_drop_na.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hhb, hbo2 합 = 헤모글로빈 양\n",
    "gap_feature_names=[]\n",
    "\n",
    "gap_feature_names.append('hhb_hbo2_add')\n",
    "\n",
    "test_1=pd.DataFrame(np.array(x_train_sample['hhb']) + np.array(x_train_sample['hbo2']), columns=gap_feature_names, index=x_train_sample.index)\n",
    "test_2=pd.DataFrame(np.array(x_train_sample_drop_na['hhb']) + np.array(x_train_sample_drop_na['hbo2']), columns=gap_feature_names, index=x_train_sample_drop_na.index)\n",
    "test_3=pd.DataFrame(np.array(test_sample['hhb']) + np.array(test_sample['hbo2']), columns=gap_feature_names, index=test_sample.index)\n",
    "\n",
    "test_4=pd.DataFrame(np.array(x_train_sample_10['hhb']) + np.array(x_train_sample_10['hbo2']), columns=gap_feature_names, index=x_train_sample_10.index)\n",
    "test_5=pd.DataFrame(np.array(x_train_sample_15['hhb']) + np.array(x_train_sample_15['hbo2']), columns=gap_feature_names, index=x_train_sample_15.index)\n",
    "test_6=pd.DataFrame(np.array(x_train_sample_20['hhb']) + np.array(x_train_sample_20['hbo2']), columns=gap_feature_names, index=x_train_sample_20.index)\n",
    "test_7=pd.DataFrame(np.array(x_train_sample_25['hhb']) + np.array(x_train_sample_25['hbo2']), columns=gap_feature_names, index=x_train_sample_25.index)\n",
    "\n",
    "\n",
    "\n",
    "x_train_sample=pd.concat((x_train_sample, test_1), axis=1)\n",
    "x_train_sample_drop_na=pd.concat((x_train_sample_drop_na, test_2), axis=1)\n",
    "test_sample=pd.concat((test_sample, test_3), axis=1)\n",
    "\n",
    "x_train_sample_10=pd.concat((x_train_sample_10, test_4), axis=1)\n",
    "x_train_sample_15=pd.concat((x_train_sample_15, test_5), axis=1)\n",
    "x_train_sample_20=pd.concat((x_train_sample_20, test_6), axis=1)\n",
    "x_train_sample_25=pd.concat((x_train_sample_25, test_7), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hhb, hbo2 합 = 헤모글로빈 양\n",
    "gap_feature_names=[]\n",
    "\n",
    "gap_feature_names.append('hhb_hbo2_gap')\n",
    "\n",
    "test_1=pd.DataFrame(np.array(x_train_sample['hhb']) - np.array(x_train_sample['hbo2']), columns=gap_feature_names, index=x_train_sample.index)\n",
    "test_2=pd.DataFrame(np.array(x_train_sample_drop_na['hhb']) - np.array(x_train_sample_drop_na['hbo2']), columns=gap_feature_names, index=x_train_sample_drop_na.index)\n",
    "test_3=pd.DataFrame(np.array(test_sample['hhb']) - np.array(test_sample['hbo2']), columns=gap_feature_names, index=test_sample.index)\n",
    "\n",
    "test_4=pd.DataFrame(np.array(x_train_sample_10['hhb']) - np.array(x_train_sample_10['hbo2']), columns=gap_feature_names, index=x_train_sample_10.index)\n",
    "test_5=pd.DataFrame(np.array(x_train_sample_15['hhb']) - np.array(x_train_sample_15['hbo2']), columns=gap_feature_names, index=x_train_sample_15.index)\n",
    "test_6=pd.DataFrame(np.array(x_train_sample_20['hhb']) - np.array(x_train_sample_20['hbo2']), columns=gap_feature_names, index=x_train_sample_20.index)\n",
    "test_7=pd.DataFrame(np.array(x_train_sample_25['hhb']) - np.array(x_train_sample_25['hbo2']), columns=gap_feature_names, index=x_train_sample_25.index)\n",
    "\n",
    "\n",
    "\n",
    "x_train_sample=pd.concat((x_train_sample, test_1), axis=1)\n",
    "x_train_sample_drop_na=pd.concat((x_train_sample_drop_na, test_2), axis=1)\n",
    "test_sample=pd.concat((test_sample, test_3), axis=1)\n",
    "\n",
    "x_train_sample_10=pd.concat((x_train_sample_10, test_4), axis=1)\n",
    "x_train_sample_15=pd.concat((x_train_sample_15, test_5), axis=1)\n",
    "x_train_sample_20=pd.concat((x_train_sample_20, test_6), axis=1)\n",
    "x_train_sample_25=pd.concat((x_train_sample_25, test_7), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho in rho_list :\n",
    "    if rho == 10 :\n",
    "        x_train_sample_10 = rebuilddata('na',x_train_sample_10,y_train_sample_10,rho)\n",
    "        x_train_sample_10 = rebuilddata('ca',x_train_sample_10,y_train_sample_10,rho)\n",
    "    elif rho == 15 :\n",
    "        x_train_sample_15 = rebuilddata('na',x_train_sample_15,y_train_sample_15,rho)\n",
    "        x_train_sample_15 = rebuilddata('ca',x_train_sample_15,y_train_sample_15,rho)\n",
    "    elif rho == 20 :\n",
    "        x_train_sample_20 = rebuilddata('na',x_train_sample_20,y_train_sample_20,rho)\n",
    "        x_train_sample_20 = rebuilddata('ca',x_train_sample_20,y_train_sample_20,rho)\n",
    "    elif rho == 25 :\n",
    "        x_train_sample_25 = rebuilddata('na',x_train_sample_25,y_train_sample_25,rho)\n",
    "        x_train_sample_25 = rebuilddata('ca',x_train_sample_25,y_train_sample_25,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sample = copy.deepcopy(train_data)\n",
    "for rho in rho_list :\n",
    "    if rho == 10 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_10.loc[:,:]\n",
    "    elif rho == 15 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_15.loc[:,:]\n",
    "    elif rho == 20 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_20.loc[:,:]\n",
    "    elif rho == 25 :\n",
    "        x_train_sample.loc[x_train_sample.rho==rho,:] = x_train_sample_25.loc[:,:]\n",
    "        \n",
    "print(x_train_sample.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data['hhb'] = copy.deepcopy(test_sample['hhb'])\n",
    "sample_data['hbo2'] = copy.deepcopy(test_sample['hbo2'])\n",
    "sample_data['ca'] = copy.deepcopy(test_sample['ca'])\n",
    "sample_data['na'] = copy.deepcopy(test_sample['na'])\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hhb_mean = train_data.loc[:,'hhb'].mean(axis=0)\n",
    "train_hbo2_mean = train_data.loc[:,'hbo2'].mean(axis=0)\n",
    "train_ca_mean = train_data.loc[:,'ca'].mean(axis=0)\n",
    "train_na_mean = train_data.loc[:,'na'].mean(axis=0)\n",
    "print(train_hhb_mean, train_hbo2_mean, train_ca_mean, train_na_mean)\n",
    "\n",
    "train_hhb_sd = train_data.loc[:,'hhb'].std(axis=0)\n",
    "train_hbo2_sd = train_data.loc[:,'hbo2'].std(axis=0)\n",
    "train_ca_sd = train_data.loc[:,'ca'].std(axis=0)\n",
    "train_na_sd = train_data.loc[:,'na'].std(axis=0)\n",
    "print(train_hhb_sd, train_hbo2_sd, train_ca_sd, train_na_sd)\n",
    "\n",
    "sample_hhb_mean = sample_data.loc[:,'hhb'].mean(axis=0)\n",
    "sample_hbo2_mean = sample_data.loc[:,'hbo2'].mean(axis=0)\n",
    "sample_ca_mean = sample_data.loc[:,'ca'].mean(axis=0)\n",
    "sample_na_mean = sample_data.loc[:,'na'].mean(axis=0)\n",
    "print(sample_hhb_mean, sample_hbo2_mean, sample_ca_mean, sample_na_mean)\n",
    "\n",
    "sample_hhb_sd = sample_data.loc[:,'hhb'].std(axis=0)\n",
    "sample_hbo2_sd = sample_data.loc[:,'hbo2'].std(axis=0)\n",
    "sample_ca_sd = sample_data.loc[:,'ca'].std(axis=0)\n",
    "sample_na_sd = sample_data.loc[:,'na'].std(axis=0)\n",
    "print(sample_hhb_sd, sample_hbo2_sd, sample_ca_sd, sample_na_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_sample_data = copy.deepcopy(sample_data)\n",
    "post_sample_data['rho'] = test_data['rho']\n",
    "for col in ['hhb','hbo2','ca','na']:\n",
    "    train_mean = train_data.loc[:,col].mean(axis=0)\n",
    "    train_sd = train_data.loc[:,col].std(axis=0)\n",
    "    sample_mean = post_sample_data.loc[:,col].mean(axis=0)\n",
    "    sample_sd = post_sample_data.loc[:,col].std(axis=0)\n",
    "    if col == 'na' :\n",
    "        for i in range(len(post_sample_data)) :\n",
    "            rho = post_sample_data.loc[i,'rho']\n",
    "            if(rho == 10) :\n",
    "                test_sample_sd = sample_sd * 1.2\n",
    "                post_sample_data.loc[i,col] = ((post_sample_data.loc[i,col]-sample_mean)*(train_sd/test_sample_sd))+train_mean\n",
    "            elif rho == 15 :\n",
    "                test_sample_sd = sample_sd*0.97\n",
    "                post_sample_data.loc[i,col] = ((post_sample_data.loc[i,col]-sample_mean)*(train_sd/test_sample_sd))+train_mean\n",
    "            elif rho == 20 :\n",
    "                test_sample_sd = sample_sd*0.7\n",
    "                post_sample_data.loc[i,col] = ((post_sample_data.loc[i,col]-sample_mean)*(train_sd/test_sample_sd))+train_mean\n",
    "            elif rho == 25 :\n",
    "                test_sample_sd = sample_sd*0.6\n",
    "                post_sample_data.loc[i,col] = ((post_sample_data.loc[i,col]-sample_mean)*(train_sd/test_sample_sd))+train_mean\n",
    "            \n",
    "    else :\n",
    "        sample_sd = post_sample_data.loc[:,col].std(axis=0)\n",
    "        post_sample_data[col] = ((post_sample_data[col]-sample_mean)*(train_sd/sample_sd))+train_mean\n",
    "    \n",
    "    post_sample_data[col].loc[(post_sample_data[col] < 0)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_data.to_csv('Dacon_Geonho_20200624_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hhb')\n",
    "print(train_data.loc[:,'hhb'].mean(axis=0, skipna=False))\n",
    "print(post_sample_data.loc[:,'hhb'].mean(axis=0, skipna=False))\n",
    "print('hbo2')\n",
    "print(train_data.loc[:,'hbo2'].mean(axis=0, skipna=False))\n",
    "print(post_sample_data.loc[:,'hbo2'].mean(axis=0, skipna=False))\n",
    "print('ca')\n",
    "print(train_data.loc[:,'ca'].mean(axis=0, skipna=False))\n",
    "print(post_sample_data.loc[:,'ca'].mean(axis=0, skipna=False))\n",
    "print('na')\n",
    "print(train_data.loc[:,'na'].mean(axis=0, skipna=False))\n",
    "print(post_sample_data.loc[:,'na'].mean(axis=0, skipna=False))\n",
    "\n",
    "print('hhb')\n",
    "print(train_data.loc[:,'hhb'].var())\n",
    "print(post_sample_data.loc[:,'hhb'].var())\n",
    "print('hbo2')\n",
    "print(train_data.loc[:,'hbo2'].var())\n",
    "print(post_sample_data.loc[:,'hbo2'].var())\n",
    "print('ca')\n",
    "print(train_data.loc[:,'ca'].var())\n",
    "print(post_sample_data.loc[:,'ca'].var())\n",
    "print('na')\n",
    "print(train_data.loc[:,'na'].var())\n",
    "print(post_sample_data.loc[:,'na'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data[\"hhb\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[\"hhb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data[\"hbo2\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[\"hbo2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data[\"ca\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[\"ca\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_data['rho'] == 10\n",
    "idx_sample = post_sample_data['rho'] == 10\n",
    "sns.distplot(train_data[idx][\"na\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[idx_sample][\"na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_data['rho'] == 15\n",
    "idx_sample = post_sample_data['rho'] == 15\n",
    "sns.distplot(train_data[idx][\"na\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[idx_sample][\"na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_data['rho'] == 20\n",
    "idx_sample = post_sample_data['rho'] == 20\n",
    "sns.distplot(train_data[idx][\"na\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[idx_sample][\"na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_data['rho'] == 25\n",
    "idx_sample = post_sample_data['rho'] == 25\n",
    "sns.distplot(train_data[idx][\"na\"], color = \"r\")\n",
    "sns.distplot(post_sample_data[idx_sample][\"na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = copy.deepcopy(post_sample_data)\n",
    "for col in models:\n",
    "    print(col)\n",
    "    if (col == 'hhb')or(col == 'hbo2') :\n",
    "        preds = []\n",
    "        for model in models[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(x_train_sample.loc[:, 'rho':'990_dst_fft_imag'])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "        test_1[col] = pred\n",
    "    else :\n",
    "        preds = []\n",
    "        for model in models[col]:\n",
    "            preds.append(model.predict(xgb.DMatrix(x_train_sample.loc[:, 'rho':])))\n",
    "        pred = np.mean(preds, axis=0)\n",
    "        test_1[col] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_data['hhb'] , test_1['hhb']\n",
    "sns.regplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_data['hbo2'] , test_1['hbo2']\n",
    "sns.regplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_data['ca'] , test_1['ca']\n",
    "sns.regplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_data['na'] , test_1['na']\n",
    "sns.regplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
